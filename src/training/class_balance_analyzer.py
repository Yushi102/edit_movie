"""
Class Balance Analyzer

å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã‚’åˆ†æã—ã€é©åˆ‡ãªLossé‡ã¿ä»˜ã‘ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
"""
import numpy as np
import torch
import logging
from typing import Dict, Tuple
from pathlib import Path

logger = logging.getLogger(__name__)


class ClassBalanceAnalyzer:
    """ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã®åˆ†æ"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        pass
    
    def analyze_dataset(
        self,
        data_path: str,
        num_tracks: int = 20
    ) -> Dict[str, any]:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã‚’åˆ†æ
        
        Args:
            data_path: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆ.npzï¼‰
            num_tracks: ãƒˆãƒ©ãƒƒã‚¯æ•°
        
        Returns:
            åˆ†æçµæœã®è¾æ›¸
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"Analyzing class balance: {data_path}")
        logger.info(f"{'='*80}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
        data = np.load(data_path)
        sequences = data['sequences']  # (num_samples, seq_len, 917) - integrated data
        
        num_samples, seq_len, total_features = sequences.shape
        
        logger.info(f"Dataset shape: {sequences.shape}")
        logger.info(f"  Samples: {num_samples}")
        logger.info(f"  Sequence length: {seq_len}")
        logger.info(f"  Total features: {total_features}")
        
        # Extract track features only (last 180 dimensions)
        # 917 = audio(215) + visual(522) + track(180)
        audio_dim = 215
        visual_dim = 522
        track_dim = 180
        
        track_sequences = sequences[:, :, audio_dim + visual_dim:]  # (num_samples, seq_len, 180)
        logger.info(f"  Track features extracted: {track_sequences.shape}")
        
        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒˆãƒ©ãƒƒã‚¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åˆ†è§£
        # (num_samples, seq_len, num_tracks, 9)
        reshaped = track_sequences.reshape(num_samples, seq_len, num_tracks, 9)
        
        # ActiveçŠ¶æ…‹ã‚’æŠ½å‡ºï¼ˆ0ç•ªç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        active_labels = reshaped[:, :, :, 0]  # (num_samples, seq_len, num_tracks)
        
        # Asset IDã‚’æŠ½å‡ºï¼ˆ1ç•ªç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        asset_labels = reshaped[:, :, :, 1]  # (num_samples, seq_len, num_tracks)
        
        # ActiveçŠ¶æ…‹ã®åˆ†æ
        active_stats = self._analyze_active_balance(active_labels)
        
        # Asset IDã®åˆ†æ
        asset_stats = self._analyze_asset_balance(asset_labels, active_labels)
        
        # æ¨å¥¨ã•ã‚Œã‚‹é‡ã¿ä»˜ã‘ã‚’è¨ˆç®—
        recommended_weights = self._calculate_recommended_weights(
            active_stats, asset_stats
        )
        
        return {
            'active_stats': active_stats,
            'asset_stats': asset_stats,
            'recommended_weights': recommended_weights
        }
    
    def _analyze_active_balance(
        self,
        active_labels: np.ndarray
    ) -> Dict[str, float]:
        """
        ActiveçŠ¶æ…‹ã®ä¸å‡è¡¡ã‚’åˆ†æ
        
        Args:
            active_labels: (num_samples, seq_len, num_tracks)
        
        Returns:
            çµ±è¨ˆæƒ…å ±
        """
        logger.info("\n--- Active State Analysis ---")
        
        # ãƒ•ãƒ©ãƒƒãƒˆåŒ–
        flat_labels = active_labels.reshape(-1)
        
        # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ã‚«ã‚¦ãƒ³ãƒˆ
        inactive_count = np.sum(flat_labels == 0)
        active_count = np.sum(flat_labels == 1)
        total_count = len(flat_labels)
        
        # æ¯”ç‡
        inactive_ratio = inactive_count / total_count
        active_ratio = active_count / total_count
        
        # ä¸å‡è¡¡æ¯”ç‡
        imbalance_ratio = inactive_count / (active_count + 1e-8)
        
        logger.info(f"  Inactive (0): {inactive_count:,} ({inactive_ratio*100:.2f}%)")
        logger.info(f"  Active (1):   {active_count:,} ({active_ratio*100:.2f}%)")
        logger.info(f"  Imbalance ratio (inactive/active): {imbalance_ratio:.2f}")
        
        if imbalance_ratio > 2.0:
            logger.warning(f"  âš ï¸  Significant class imbalance detected!")
            logger.warning(f"     Inactive frames are {imbalance_ratio:.1f}x more common than active frames")
        
        return {
            'inactive_count': int(inactive_count),
            'active_count': int(active_count),
            'inactive_ratio': float(inactive_ratio),
            'active_ratio': float(active_ratio),
            'imbalance_ratio': float(imbalance_ratio)
        }
    
    def _analyze_asset_balance(
        self,
        asset_labels: np.ndarray,
        active_labels: np.ndarray
    ) -> Dict[str, any]:
        """
        Asset IDã®ä¸å‡è¡¡ã‚’åˆ†æ
        
        Args:
            asset_labels: (num_samples, seq_len, num_tracks)
            active_labels: (num_samples, seq_len, num_tracks)
        
        Returns:
            çµ±è¨ˆæƒ…å ±
        """
        logger.info("\n--- Asset ID Analysis ---")
        
        # Activeãªãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’å¯¾è±¡
        active_mask = active_labels == 1
        active_assets = asset_labels[active_mask]
        
        if len(active_assets) == 0:
            logger.warning("  No active frames found!")
            return {
                'asset_counts': {},
                'asset_ratios': {},
                'num_unique_assets': 0
            }
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªAsset IDã¨ãã®ã‚«ã‚¦ãƒ³ãƒˆ
        unique_assets, counts = np.unique(active_assets, return_counts=True)
        
        # çµ±è¨ˆ
        asset_counts = {int(asset_id): int(count) for asset_id, count in zip(unique_assets, counts)}
        asset_ratios = {int(asset_id): float(count / len(active_assets)) for asset_id, count in zip(unique_assets, counts)}
        
        logger.info(f"  Number of unique assets: {len(unique_assets)}")
        logger.info(f"  Asset distribution:")
        
        # ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤º
        sorted_assets = sorted(asset_counts.items(), key=lambda x: x[1], reverse=True)
        for asset_id, count in sorted_assets[:10]:  # ä¸Šä½10å€‹
            ratio = asset_ratios[asset_id]
            logger.info(f"    Asset {asset_id}: {count:,} ({ratio*100:.2f}%)")
        
        if len(sorted_assets) > 10:
            logger.info(f"    ... and {len(sorted_assets) - 10} more")
        
        # ä¸å‡è¡¡ã®æ¤œå‡º
        max_count = max(counts)
        min_count = min(counts)
        asset_imbalance = max_count / (min_count + 1e-8)
        
        if asset_imbalance > 5.0:
            logger.warning(f"  âš ï¸  Asset imbalance detected!")
            logger.warning(f"     Most common asset is {asset_imbalance:.1f}x more frequent than least common")
        
        return {
            'asset_counts': asset_counts,
            'asset_ratios': asset_ratios,
            'num_unique_assets': int(len(unique_assets)),
            'asset_imbalance': float(asset_imbalance)
        }
    
    def _calculate_recommended_weights(
        self,
        active_stats: Dict,
        asset_stats: Dict
    ) -> Dict[str, float]:
        """
        æ¨å¥¨ã•ã‚Œã‚‹Lossé‡ã¿ä»˜ã‘ã‚’è¨ˆç®—
        
        Args:
            active_stats: ActiveçŠ¶æ…‹ã®çµ±è¨ˆ
            asset_stats: Asset IDã®çµ±è¨ˆ
        
        Returns:
            æ¨å¥¨ã•ã‚Œã‚‹é‡ã¿ä»˜ã‘
        """
        logger.info("\n--- Recommended Loss Weights ---")
        
        # Activeé‡ã¿: ä¸å‡è¡¡æ¯”ç‡ã«åŸºã¥ã„ã¦èª¿æ•´
        # ä¸å‡è¡¡ãŒå¤§ãã„ã»ã©ã€Activeã‚¯ãƒ©ã‚¹ã®é‡ã¿ã‚’å¢—ã‚„ã™
        imbalance_ratio = active_stats['imbalance_ratio']
        
        if imbalance_ratio > 2.0:
            # ä¸å‡è¡¡ãŒã‚ã‚‹å ´åˆã¯ã€Activeã‚¯ãƒ©ã‚¹ã®é‡ã¿ã‚’å¢—ã‚„ã™
            # ãŸã ã—ã€æ¥µç«¯ãªå€¤ã«ãªã‚‰ãªã„ã‚ˆã†ã«åˆ¶é™
            active_weight = min(imbalance_ratio / 2.0, 5.0)
        else:
            active_weight = 1.0
        
        # Asseté‡ã¿: Activeã¨åŒç¨‹åº¦
        asset_weight = 1.0
        
        # å›å¸°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡ã¿: Activeãªãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã§è¨ˆç®—ã•ã‚Œã‚‹ãŸã‚ã€
        # ActiveãŒå°‘ãªã„å ´åˆã¯ç›¸å¯¾çš„ã«é‡è¦åº¦ã‚’ä¸Šã’ã‚‹
        if active_stats['active_ratio'] < 0.3:
            # ActiveãŒ30%æœªæº€ã®å ´åˆã¯å›å¸°ã®é‡ã¿ã‚’ä¸Šã’ã‚‹
            regression_weight = 1.5
        else:
            regression_weight = 1.0
        
        recommended = {
            'active_weight': float(active_weight),
            'asset_weight': float(asset_weight),
            'scale_weight': float(regression_weight),
            'position_weight': float(regression_weight),
            'rotation_weight': float(regression_weight),
            'crop_weight': float(regression_weight)
        }
        
        logger.info("  Recommended weights:")
        for key, value in recommended.items():
            logger.info(f"    {key}: {value:.2f}")
        
        # èª¬æ˜
        if active_weight > 1.0:
            logger.info(f"\n  ğŸ’¡ Active weight increased to {active_weight:.2f} due to class imbalance")
            logger.info(f"     This will help the model learn to predict active frames better")
        
        if regression_weight > 1.0:
            logger.info(f"\n  ğŸ’¡ Regression weights increased to {regression_weight:.2f}")
            logger.info(f"     This compensates for fewer active frames to learn from")
        
        logger.info(f"{'='*80}\n")
        
        return recommended


def analyze_and_save_weights(
    train_data_path: str,
    output_path: str,
    num_tracks: int = 20
) -> Dict[str, float]:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†æã—ã¦æ¨å¥¨é‡ã¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    
    Args:
        train_data_path: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        num_tracks: ãƒˆãƒ©ãƒƒã‚¯æ•°
    
    Returns:
        æ¨å¥¨ã•ã‚Œã‚‹é‡ã¿ä»˜ã‘
    """
    analyzer = ClassBalanceAnalyzer()
    results = analyzer.analyze_dataset(train_data_path, num_tracks)
    
    # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    import yaml
    
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        yaml.dump(results['recommended_weights'], f, default_flow_style=False)
    
    logger.info(f"Recommended weights saved to: {output_path}")
    
    return results['recommended_weights']


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆ
    logging.basicConfig(level=logging.INFO)
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
    num_samples = 10
    seq_len = 100
    num_tracks = 20
    
    # ä¸å‡è¡¡ãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    sequences = np.zeros((num_samples, seq_len, num_tracks * 12))
    
    # ActiveçŠ¶æ…‹ã‚’è¨­å®šï¼ˆ20%ã®ã¿Activeï¼‰
    for i in range(num_samples):
        for t in range(seq_len):
            for track in range(num_tracks):
                if np.random.rand() < 0.2:  # 20%ã®ç¢ºç‡ã§Active
                    idx = track * 12
                    sequences[i, t, idx] = 1  # Active
                    sequences[i, t, idx + 1] = np.random.randint(0, 10)  # Asset ID
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    temp_path = "temp_test_data.npz"
    np.savez(temp_path, sequences=sequences)
    
    # åˆ†æ
    analyzer = ClassBalanceAnalyzer()
    results = analyzer.analyze_dataset(temp_path, num_tracks=20)
    
    print("\nâœ… Analysis complete!")
    print(f"Recommended active_weight: {results['recommended_weights']['active_weight']:.2f}")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    import os
    os.remove(temp_path)
