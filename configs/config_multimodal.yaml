# Multimodal Multi-Track Transformer Training Configuration

# Data paths
train_data: preprocessed_data/train_sequences.npz
val_data: preprocessed_data/val_sequences.npz
features_dir: input_features  # Directory containing video feature CSV files

# Multimodal settings
enable_multimodal: true
fusion_type: gated  # Options: concat, add, gated, attention
use_modality_attention_mask: true  # Mask unavailable modalities in attention

# Feature dimensions
audio_features: 5  # RMS, is_speaking, silence_duration, text_is_active (numerical only)
visual_features: 522  # 10 scalar features + 512 CLIP embeddings
track_features: 180  # 20 tracks Ã— 9 parameters

# Model architecture
d_model: 256
nhead: 8
num_encoder_layers: 6
dim_feedforward: 1024
dropout: 0.1
num_tracks: 20
max_asset_classes: 10

# Training hyperparameters
batch_size: 16
num_epochs: 100
learning_rate: 0.0001
weight_decay: 0.00001
grad_clip: 1.0

# Optimizer and scheduler
optimizer: adam  # adam, adamw, sgd
scheduler: cosine  # cosine, step, plateau, none
warmup_epochs: 5
min_lr: 0.000001

# Loss weights
active_weight: 1.0
asset_weight: 1.0
scale_weight: 1.0
position_weight: 1.0
crop_weight: 1.0
ignore_inactive: true

# Checkpointing
checkpoint_dir: checkpoints_multimodal
save_every: 5
early_stopping_patience: null  # null = disabled, or set to number of epochs

# Data loading
num_workers: 0

# Device
cpu: false  # Set to true to force CPU training

# Feature alignment settings
alignment_tolerance: 0.05  # Seconds - tolerance for timestamp matching
max_interpolation_ratio: 0.5  # Warn if >50% of values are interpolated
max_gap_seconds: 5.0  # Warn if gaps larger than this exist

# Memory optimization
use_fp16_visual: true  # Store visual features as float16 to save memory
lazy_loading: true  # Load features on-demand rather than all at once
cache_aligned_features: true  # Cache aligned features to avoid repeated interpolation
